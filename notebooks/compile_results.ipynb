{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import typing\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_header(segment):\n",
    "    if segment.startswith('model_args:'):\n",
    "        return segment[len('model_args:'):]\n",
    "    elif segment.startswith('task_args:'):\n",
    "        return segment[len('task_args:'):]\n",
    "    else:\n",
    "        return segment\n",
    "\n",
    "def parse_segment(segment) -> typing.List[str]:\n",
    "    segment = remove_header(segment)\n",
    "    kwargs = [kwarg for kwarg in segment.split(',') if kwarg]\n",
    "    args = {}\n",
    "    for kwarg_str in kwargs:\n",
    "        k,v = kwarg_str.split('=')\n",
    "        args[k] = v if v != 'None' else None\n",
    "    return args\n",
    "\n",
    "def parse_fname(fname: str) -> typing.Dict:    \n",
    "    args = {}\n",
    "    for segment in fname.split('|'):\n",
    "        args.update(parse_segment(segment))\n",
    "    return args\n",
    "\n",
    "def parse_file(fpath: str) -> typing.Dict:\n",
    "    mtime = os.stat(fpath).st_mtime\n",
    "    with open(fpath, 'rt') as f:\n",
    "        o = json.load(f)\n",
    "    task_version = o['versions']\n",
    "    d = {'mtime': mtime}\n",
    "    for k, v in o['config'].items():\n",
    "        if isinstance(v, str) and '=' in v:\n",
    "            d.update(parse_segment(v))\n",
    "        elif not v and k in ['model_args', 'task_args']:\n",
    "            continue\n",
    "        else:\n",
    "            d[k] = v\n",
    "    for task_name, results in o['results'].items():\n",
    "        if task_name.endswith('_d'):\n",
    "            task_name_out = task_name[:-len('_d')]\n",
    "        elif task_name.endswith('_dg'):\n",
    "            task_name_out = task_name[:-len('_dg')]\n",
    "        else:\n",
    "            task_name_out = task_name\n",
    "        for k, v in results.items():\n",
    "            # d[f'{task_name_out}_v{task_version[task_name]}:{k}'] = v\n",
    "            d[f'{task_name_out}:{k}'] = v\n",
    "    return d\n",
    "\n",
    "def parse_dir(dirpath: str) -> pd.DataFrame:\n",
    "    # pd.DataFrame([parse_fname(fname) for fname in os.listdir('lmeval_results')])\n",
    "    fnames, mtimes = zip(*[(fentry.name, fentry.stat().st_mtime) for fentry in os.scandir(dirpath) if fentry.is_file() and fentry.name.endswith('.json')])\n",
    "    return pd.DataFrame([parse_file(f'{dirpath}/{fname}') for fname in fnames])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(dir: str = '../lmeval_results') -> pd.DataFrame:\n",
    "    df = parse_dir(dir)\n",
    "    df = df[[col for col in df.columns if col not in ['batch_size', 'device', 'no_cache', 'bootstrap_iters', 'description_dict']]]\n",
    "    df = df.drop(columns='limit').assign(pretrained=df.pretrained.fillna('GPT2'))\n",
    "    df = df.assign(model_type=df.model.map(lambda model: 'autoregressive' if model == 'gpt2' else (model))).drop(columns='model')\n",
    "    return df\n",
    "\n",
    "def task_metrics(results_df: pd.DataFrame, tasks: typing.List[str]) -> pd.DataFrame:\n",
    "    metrics = tasks\n",
    "    metrics_re = re.compile(r'^(' + r'|'.join([f'({m})' for m in metrics]) + ').*' )\n",
    "    model_cols = {'model_type', 'pretrained', 'WORD_AGG_SCHEME', 'SIMILARITY_FUNC', 'NORM'}\n",
    "    task_cols = {'num_fewshot', 'encoding_scheme'}\n",
    "    metric_cols = {col for col in df.columns if metrics_re.fullmatch(col) is not None}\n",
    "    selected_cols = model_cols | task_cols | metric_cols | {'mtime'}\n",
    "    if (selected_cols) < set(df.columns):\n",
    "        f'Following columns were unaccounted: {set(results_df.columns) - selected_cols}'\n",
    "    groupby_cols = (model_cols | task_cols)\n",
    "    def take_last(_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        _df = _df.sort_values(by='mtime', ascending=False)\n",
    "        return pd.Series({col: _df[col].dropna().iloc[0] if _df[col].dropna().shape[0] >=1 else None for col in _df.columns if col in metric_cols})\n",
    "    df2 = results_df[list(selected_cols)].groupby(list(groupby_cols), dropna=False).aggregate(take_last).dropna(how='all')\n",
    "    return df2.reset_index().dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1842477/135995605.py:21: FutureWarning: Dropping invalid columns in DataFrameGroupBy.agg is deprecated. In a future version, a TypeError will be raised. Before calling .agg, select only columns which should be valid for the function.\n",
      "  df2 = results_df[list(selected_cols)].groupby(list(groupby_cols), dropna=False).aggregate(take_last).dropna(how='all')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoding_scheme</th>\n",
       "      <th>model_type</th>\n",
       "      <th>num_fewshot</th>\n",
       "      <th>pretrained</th>\n",
       "      <th>webqs:acc_stderr</th>\n",
       "      <th>webqs:acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cross_encoding</td>\n",
       "      <td>dist_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.016732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cross_encoding</td>\n",
       "      <td>dist_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cross_encoding</td>\n",
       "      <td>dist_gen</td>\n",
       "      <td>5</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.068406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cross_encoding</td>\n",
       "      <td>dist_gen</td>\n",
       "      <td>5</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.022638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cross_encoding</td>\n",
       "      <td>dist_gen</td>\n",
       "      <td>25</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.026083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>autoregressive</td>\n",
       "      <td>0</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.016732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>autoregressive</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>autoregressive</td>\n",
       "      <td>5</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.068406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>autoregressive</td>\n",
       "      <td>5</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.022638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>autoregressive</td>\n",
       "      <td>25</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>0.095472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>autoregressive</td>\n",
       "      <td>25</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.026083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encoding_scheme      model_type  num_fewshot               pretrained  \\\n",
       "0   cross_encoding        dist_gen            0  EleutherAI/gpt-neo-1.3B   \n",
       "1   cross_encoding        dist_gen            0                     GPT2   \n",
       "2   cross_encoding        dist_gen            5  EleutherAI/gpt-neo-1.3B   \n",
       "3   cross_encoding        dist_gen            5                     GPT2   \n",
       "4   cross_encoding        dist_gen           25                     GPT2   \n",
       "5              NaN  autoregressive            0  EleutherAI/gpt-neo-1.3B   \n",
       "6              NaN  autoregressive            0                     GPT2   \n",
       "7              NaN  autoregressive            5  EleutherAI/gpt-neo-1.3B   \n",
       "8              NaN  autoregressive            5                     GPT2   \n",
       "9              NaN  autoregressive           25  EleutherAI/gpt-neo-1.3B   \n",
       "10             NaN  autoregressive           25                     GPT2   \n",
       "\n",
       "    webqs:acc_stderr  webqs:acc  \n",
       "0           0.002846   0.016732  \n",
       "1           0.001204   0.002953  \n",
       "2           0.005601   0.068406  \n",
       "3           0.003301   0.022638  \n",
       "4           0.003537   0.026083  \n",
       "5           0.002846   0.016732  \n",
       "6           0.001204   0.002953  \n",
       "7           0.005601   0.068406  \n",
       "8           0.003301   0.022638  \n",
       "9           0.006521   0.095472  \n",
       "10          0.003537   0.026083  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_results()\n",
    "df_webqs = task_metrics(df, ['webqs'])\n",
    "df_webqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoding_scheme</th>\n",
       "      <th>model_type</th>\n",
       "      <th>num_fewshot</th>\n",
       "      <th>pretrained</th>\n",
       "      <th>webqs:acc_stderr</th>\n",
       "      <th>webqs:acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cross_encoding</td>\n",
       "      <td>dist_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.016732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cross_encoding</td>\n",
       "      <td>dist_gen</td>\n",
       "      <td>5</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.068406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>autoregressive</td>\n",
       "      <td>0</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.016732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>autoregressive</td>\n",
       "      <td>5</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.068406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>autoregressive</td>\n",
       "      <td>25</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>0.095472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  encoding_scheme      model_type  num_fewshot               pretrained  \\\n",
       "0  cross_encoding        dist_gen            0  EleutherAI/gpt-neo-1.3B   \n",
       "2  cross_encoding        dist_gen            5  EleutherAI/gpt-neo-1.3B   \n",
       "5             NaN  autoregressive            0  EleutherAI/gpt-neo-1.3B   \n",
       "7             NaN  autoregressive            5  EleutherAI/gpt-neo-1.3B   \n",
       "9             NaN  autoregressive           25  EleutherAI/gpt-neo-1.3B   \n",
       "\n",
       "   webqs:acc_stderr  webqs:acc  \n",
       "0          0.002846   0.016732  \n",
       "2          0.005601   0.068406  \n",
       "5          0.002846   0.016732  \n",
       "7          0.005601   0.068406  \n",
       "9          0.006521   0.095472  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_webqs[(df_webqs.pretrained == 'EleutherAI/gpt-neo-1.3B')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lme",
   "language": "python",
   "name": "lme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a9a0c18e9779ed2e58fb5ce841cff9e897a8be01ea55109e48089b82d3eb788"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

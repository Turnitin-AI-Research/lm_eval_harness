{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import typing\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_header(segment):\n",
    "    if segment.startswith('model_args:'):\n",
    "        return segment[len('model_args:'):]\n",
    "    elif segment.startswith('task_args:'):\n",
    "        return segment[len('task_args:'):]\n",
    "    else:\n",
    "        return segment\n",
    "\n",
    "def parse_segment(segment) -> typing.List[str]:\n",
    "    segment = remove_header(segment)\n",
    "    kwargs = [kwarg for kwarg in segment.split(',') if kwarg]\n",
    "    args = {}\n",
    "    for kwarg_str in kwargs:\n",
    "        k,v = kwarg_str.split('=')\n",
    "        args[k] = v if v != 'None' else None\n",
    "    return args\n",
    "\n",
    "def parse_fname(fname: str) -> typing.Dict:    \n",
    "    args = {}\n",
    "    for segment in fname.split('|'):\n",
    "        args.update(parse_segment(segment))\n",
    "    return args\n",
    "\n",
    "def parse_file(fpath: str) -> typing.Dict:\n",
    "    mtime = os.stat(fpath).st_mtime\n",
    "    with open(fpath, 'rt') as f:\n",
    "        o = json.load(f)\n",
    "    task_version = o['versions']\n",
    "    d = {'mtime': mtime}\n",
    "    for k, v in o['config'].items():\n",
    "        if isinstance(v, str) and '=' in v:\n",
    "            d.update(parse_segment(v))\n",
    "        elif not v and k in ['model_args', 'task_args']:\n",
    "            continue\n",
    "        else:\n",
    "            d[k] = v\n",
    "    for task_name, results in o['results'].items():\n",
    "        if task_name.endswith('_d'):\n",
    "            task_name_out = task_name[:-len('_d')]\n",
    "        elif task_name.endswith('_dg'):\n",
    "            task_name_out = task_name[:-len('_dg')]\n",
    "        else:\n",
    "            task_name_out = task_name\n",
    "        for k, v in results.items():\n",
    "            # d[f'{task_name_out}_v{task_version[task_name]}:{k}'] = v\n",
    "            d[f'{task_name_out}:{k}'] = v\n",
    "    return d\n",
    "\n",
    "def parse_dir(dirpath: str) -> pd.DataFrame:\n",
    "    # pd.DataFrame([parse_fname(fname) for fname in os.listdir('lmeval_results')])\n",
    "    fnames, mtimes = zip(*[(fentry.name, fentry.stat().st_mtime) for fentry in os.scandir(dirpath) if fentry.is_file() and fentry.name.endswith('.json')])\n",
    "    return pd.DataFrame([parse_file(f'{dirpath}/{fname}') for fname in fnames])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(dir: str = '../lmeval_results3') -> pd.DataFrame:\n",
    "    df = parse_dir(dir)\n",
    "    df = df[[col for col in df.columns if col not in ['batch_size', 'device', 'no_cache', 'bootstrap_iters', 'description_dict']]]\n",
    "    df = df.drop(columns='limit').assign(pretrained=df.pretrained.fillna('GPT2'))\n",
    "    df = df.assign(model_type=df.model.map(lambda model: 'autoregressive' if model == 'gpt2' else (model))).drop(columns='model')\n",
    "    return df\n",
    "\n",
    "def task_metrics(results_df: pd.DataFrame, tasks: typing.List[str]) -> pd.DataFrame:\n",
    "    metrics = tasks\n",
    "    metrics_re = re.compile(r'^(' + r'|'.join([f'({m})' for m in metrics]) + ').*' )\n",
    "    print(f'metric cols regexp = {metrics_re}')\n",
    "    model_cols = {'model_type', 'pretrained', 'WORD_AGG_SCHEME', 'SEGMENT_AGG_SCHEME', 'EXAMPLE_AGG_SCHEME', 'SIMILARITY_FUNC', 'NORM', 'COMPOSITION_FUNC'}\n",
    "    task_cols = {'num_fewshot', 'encoding_scheme'}\n",
    "    # metric_cols = {col for col in df.columns if metrics_re.fullmatch(col) is not None}\n",
    "    task_metric_cols = {task: [col for col in df.columns if re.fullmatch(f'^{task}.*', col)] for task in tasks}\n",
    "    metric_cols = {col for cols in task_metric_cols.values() for col in cols}\n",
    "    selected_cols = model_cols | task_cols | metric_cols | {'mtime'}\n",
    "    if (selected_cols) < set(df.columns):\n",
    "        print(f'Following columns will be dropped: {set(results_df.columns) - selected_cols}')\n",
    "    groupby_cols = (model_cols | task_cols)\n",
    "    def take_last(_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        _df = _df.sort_values(by='mtime', ascending=False)\n",
    "        # return pd.Series({col: _df[col].dropna().iloc[0] if _df[col].dropna().shape[0] >=1 else None for col in _df.columns if col in metric_cols})\n",
    "        return pd.concat([_df[task_metric_cols[task]].dropna().iloc[0] for task in tasks])\n",
    "    df2 = results_df[list(selected_cols)].groupby(list(groupby_cols), dropna=False).aggregate(take_last).dropna(how='all')\n",
    "    return df2.reset_index().dropna(axis=1, how='all').sort_values(by=['num_fewshot', 'pretrained', 'model_type'])\n",
    "df = read_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show All Files Individually Without Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mtime</th>\n",
       "      <th>WORD_AGG_SCHEME</th>\n",
       "      <th>EXAMPLE_AGG_SCHEME</th>\n",
       "      <th>SEGMENT_AGG_SCHEME</th>\n",
       "      <th>NORM</th>\n",
       "      <th>SIMILARITY_FUNC</th>\n",
       "      <th>pretrained</th>\n",
       "      <th>encoding_scheme</th>\n",
       "      <th>num_fewshot</th>\n",
       "      <th>hellaswag:acc</th>\n",
       "      <th>hellaswag:acc_stderr</th>\n",
       "      <th>hellaswag:rand_acc</th>\n",
       "      <th>hellaswag:rand_acc_stderr</th>\n",
       "      <th>COMPOSITION_FUNC</th>\n",
       "      <th>model_type</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.668194e+09</td>\n",
       "      <td>last</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>layer</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>segment_each_example</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272655</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>soft_cluster</td>\n",
       "      <td>dist_sim</td>\n",
       "      <td>2022-11-11 19:19:53.278054912+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.668191e+09</td>\n",
       "      <td>last</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>layer</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>concat_each_example</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272655</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_sim</td>\n",
       "      <td>2022-11-11 18:15:08.370534400+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.668129e+09</td>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>layer</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>segment_each_example</td>\n",
       "      <td>5</td>\n",
       "      <td>0.282115</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_sim</td>\n",
       "      <td>2022-11-11 01:11:01.651759616+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.668129e+09</td>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>layer</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>merge_all_segments</td>\n",
       "      <td>5</td>\n",
       "      <td>0.282115</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_sim</td>\n",
       "      <td>2022-11-11 01:06:30.934188544+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.668129e+09</td>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>layer</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>concat_each_example</td>\n",
       "      <td>5</td>\n",
       "      <td>0.285103</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_sim</td>\n",
       "      <td>2022-11-11 01:04:53.723048448+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.668128e+09</td>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>layer</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>concat_all_examples</td>\n",
       "      <td>5</td>\n",
       "      <td>0.235909</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_sim</td>\n",
       "      <td>2022-11-11 00:54:39.460186880+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.668127e+09</td>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>layer</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>concat_all_examples</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289882</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_sim</td>\n",
       "      <td>2022-11-11 00:35:20.630814208+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.668127e+09</td>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>layer</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>segment_each_example</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289882</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_sim</td>\n",
       "      <td>2022-11-11 00:34:58.115027968+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.668127e+09</td>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>layer</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>merge_all_segments</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289882</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_sim</td>\n",
       "      <td>2022-11-11 00:34:47.627127296+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.668127e+09</td>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>layer</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>concat_each_example</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289882</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_sim</td>\n",
       "      <td>2022-11-11 00:34:45.127151104+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mtime WORD_AGG_SCHEME EXAMPLE_AGG_SCHEME SEGMENT_AGG_SCHEME   NORM  \\\n",
       "4  1.668194e+09            last               None               None  layer   \n",
       "6  1.668191e+09            last               None               None  layer   \n",
       "7  1.668129e+09            mean               None               None  layer   \n",
       "9  1.668129e+09            mean               None               None  layer   \n",
       "5  1.668129e+09            mean               None               None  layer   \n",
       "1  1.668128e+09            mean               None               None  layer   \n",
       "8  1.668127e+09            mean               None               None  layer   \n",
       "0  1.668127e+09            mean               None               None  layer   \n",
       "3  1.668127e+09            mean               None               None  layer   \n",
       "2  1.668127e+09            mean               None               None  layer   \n",
       "\n",
       "  SIMILARITY_FUNC               pretrained       encoding_scheme  num_fewshot  \\\n",
       "4     dot_product  EleutherAI/gpt-neo-1.3B  segment_each_example            0   \n",
       "6     dot_product  EleutherAI/gpt-neo-1.3B   concat_each_example            0   \n",
       "7     dot_product  EleutherAI/gpt-neo-1.3B  segment_each_example            5   \n",
       "9     dot_product  EleutherAI/gpt-neo-1.3B    merge_all_segments            5   \n",
       "5     dot_product  EleutherAI/gpt-neo-1.3B   concat_each_example            5   \n",
       "1     dot_product  EleutherAI/gpt-neo-1.3B   concat_all_examples            5   \n",
       "8     dot_product  EleutherAI/gpt-neo-1.3B   concat_all_examples            0   \n",
       "0     dot_product  EleutherAI/gpt-neo-1.3B  segment_each_example            0   \n",
       "3     dot_product  EleutherAI/gpt-neo-1.3B    merge_all_segments            0   \n",
       "2     dot_product  EleutherAI/gpt-neo-1.3B   concat_each_example            0   \n",
       "\n",
       "   hellaswag:acc  hellaswag:acc_stderr  hellaswag:rand_acc  \\\n",
       "4       0.272655              0.004444                0.25   \n",
       "6       0.272655              0.004444                0.25   \n",
       "7       0.282115              0.004491                0.25   \n",
       "9       0.282115              0.004491                0.25   \n",
       "5       0.285103              0.004505                0.25   \n",
       "1       0.235909              0.004237                0.25   \n",
       "8       0.289882              0.004528                0.25   \n",
       "0       0.289882              0.004528                0.25   \n",
       "3       0.289882              0.004528                0.25   \n",
       "2       0.289882              0.004528                0.25   \n",
       "\n",
       "   hellaswag:rand_acc_stderr COMPOSITION_FUNC model_type  \\\n",
       "4                        0.0     soft_cluster   dist_sim   \n",
       "6                        0.0              NaN   dist_sim   \n",
       "7                        0.0              NaN   dist_sim   \n",
       "9                        0.0              NaN   dist_sim   \n",
       "5                        0.0              NaN   dist_sim   \n",
       "1                        0.0              NaN   dist_sim   \n",
       "8                        0.0              NaN   dist_sim   \n",
       "0                        0.0              NaN   dist_sim   \n",
       "3                        0.0              NaN   dist_sim   \n",
       "2                        0.0              NaN   dist_sim   \n",
       "\n",
       "                                 date  \n",
       "4 2022-11-11 19:19:53.278054912+00:00  \n",
       "6 2022-11-11 18:15:08.370534400+00:00  \n",
       "7 2022-11-11 01:11:01.651759616+00:00  \n",
       "9 2022-11-11 01:06:30.934188544+00:00  \n",
       "5 2022-11-11 01:04:53.723048448+00:00  \n",
       "1 2022-11-11 00:54:39.460186880+00:00  \n",
       "8 2022-11-11 00:35:20.630814208+00:00  \n",
       "0 2022-11-11 00:34:58.115027968+00:00  \n",
       "3 2022-11-11 00:34:47.627127296+00:00  \n",
       "2 2022-11-11 00:34:45.127151104+00:00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = df.assign(date=pd.to_datetime(df.mtime, unit='s', origin='unix', utc=True)).sort_values(by='mtime', ascending=False)\n",
    "all_df[all_df.mtime > 1.662555e+09]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WebQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_webqs = task_metrics(df, ['webqs'])\n",
    "# df_webqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hellaswag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric cols regexp = re.compile('^((hellaswag:acc)).*')\n",
      "Following columns will be dropped: {'hellaswag:rand_acc_stderr', 'hellaswag:rand_acc'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4191814/3550378907.py:25: FutureWarning: Dropping invalid columns in DataFrameGroupBy.agg is deprecated. In a future version, a TypeError will be raised. Before calling .agg, select only columns which should be valid for the function.\n",
      "  df2 = results_df[list(selected_cols)].groupby(list(groupby_cols), dropna=False).aggregate(take_last).dropna(how='all')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>pretrained</th>\n",
       "      <th>COMPOSITION_FUNC</th>\n",
       "      <th>SIMILARITY_FUNC</th>\n",
       "      <th>encoding_scheme</th>\n",
       "      <th>num_fewshot</th>\n",
       "      <th>WORD_AGG_SCHEME</th>\n",
       "      <th>NORM</th>\n",
       "      <th>hellaswag:acc</th>\n",
       "      <th>hellaswag:acc_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>concat_all_examples</td>\n",
       "      <td>0</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.289882</td>\n",
       "      <td>0.004528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>concat_each_example</td>\n",
       "      <td>0</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.289882</td>\n",
       "      <td>0.004528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>merge_all_segments</td>\n",
       "      <td>0</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.289882</td>\n",
       "      <td>0.004528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>segment_each_example</td>\n",
       "      <td>0</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.289882</td>\n",
       "      <td>0.004528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>soft_cluster</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>segment_each_example</td>\n",
       "      <td>0</td>\n",
       "      <td>last</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.272655</td>\n",
       "      <td>0.004444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>concat_each_example</td>\n",
       "      <td>0</td>\n",
       "      <td>last</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.272655</td>\n",
       "      <td>0.004444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>concat_each_example</td>\n",
       "      <td>5</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.285103</td>\n",
       "      <td>0.004505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>merge_all_segments</td>\n",
       "      <td>5</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.282115</td>\n",
       "      <td>0.004491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>segment_each_example</td>\n",
       "      <td>5</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.282115</td>\n",
       "      <td>0.004491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>concat_all_examples</td>\n",
       "      <td>5</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.235909</td>\n",
       "      <td>0.004237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type               pretrained COMPOSITION_FUNC SIMILARITY_FUNC  \\\n",
       "1   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "4   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "6   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "8   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "0   dist_sim  EleutherAI/gpt-neo-1.3B     soft_cluster     dot_product   \n",
       "3   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "5   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "7   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "9   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "2   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "\n",
       "        encoding_scheme  num_fewshot WORD_AGG_SCHEME   NORM  hellaswag:acc  \\\n",
       "1   concat_all_examples            0            mean  layer       0.289882   \n",
       "4   concat_each_example            0            mean  layer       0.289882   \n",
       "6    merge_all_segments            0            mean  layer       0.289882   \n",
       "8  segment_each_example            0            mean  layer       0.289882   \n",
       "0  segment_each_example            0            last  layer       0.272655   \n",
       "3   concat_each_example            0            last  layer       0.272655   \n",
       "5   concat_each_example            5            mean  layer       0.285103   \n",
       "7    merge_all_segments            5            mean  layer       0.282115   \n",
       "9  segment_each_example            5            mean  layer       0.282115   \n",
       "2   concat_all_examples            5            mean  layer       0.235909   \n",
       "\n",
       "   hellaswag:acc_stderr  \n",
       "1              0.004528  \n",
       "4              0.004528  \n",
       "6              0.004528  \n",
       "8              0.004528  \n",
       "0              0.004444  \n",
       "3              0.004444  \n",
       "5              0.004505  \n",
       "7              0.004491  \n",
       "9              0.004491  \n",
       "2              0.004237  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "df_hellaswag = task_metrics(df, ['hellaswag:acc'])\n",
    "df_hellaswag = df_hellaswag.sort_values(by=['num_fewshot', 'pretrained', 'model_type', 'hellaswag:acc'], ascending=[True, True, True, False])\n",
    "df_hellaswag[df_hellaswag['pretrained'] == 'EleutherAI/gpt-neo-1.3B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric cols regexp = re.compile('^((hellaswag:acc)|(webqs:acc)).*')\n",
      "Following columns will be dropped: {'hellaswag:rand_acc_stderr', 'hellaswag:rand_acc'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4191814/3550378907.py:25: FutureWarning: Dropping invalid columns in DataFrameGroupBy.agg is deprecated. In a future version, a TypeError will be raised. Before calling .agg, select only columns which should be valid for the function.\n",
      "  df2 = results_df[list(selected_cols)].groupby(list(groupby_cols), dropna=False).aggregate(take_last).dropna(how='all')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>pretrained</th>\n",
       "      <th>COMPOSITION_FUNC</th>\n",
       "      <th>SIMILARITY_FUNC</th>\n",
       "      <th>encoding_scheme</th>\n",
       "      <th>num_fewshot</th>\n",
       "      <th>WORD_AGG_SCHEME</th>\n",
       "      <th>NORM</th>\n",
       "      <th>hellaswag:acc</th>\n",
       "      <th>hellaswag:acc_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>soft_cluster</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>segment_each_example</td>\n",
       "      <td>0</td>\n",
       "      <td>last</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.272655</td>\n",
       "      <td>0.004444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>concat_all_examples</td>\n",
       "      <td>0</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.289882</td>\n",
       "      <td>0.004528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>concat_each_example</td>\n",
       "      <td>0</td>\n",
       "      <td>last</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.272655</td>\n",
       "      <td>0.004444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>concat_each_example</td>\n",
       "      <td>0</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.289882</td>\n",
       "      <td>0.004528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>merge_all_segments</td>\n",
       "      <td>0</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.289882</td>\n",
       "      <td>0.004528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>segment_each_example</td>\n",
       "      <td>0</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.289882</td>\n",
       "      <td>0.004528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>concat_all_examples</td>\n",
       "      <td>5</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.235909</td>\n",
       "      <td>0.004237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>concat_each_example</td>\n",
       "      <td>5</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.285103</td>\n",
       "      <td>0.004505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>merge_all_segments</td>\n",
       "      <td>5</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.282115</td>\n",
       "      <td>0.004491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dist_sim</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dot_product</td>\n",
       "      <td>segment_each_example</td>\n",
       "      <td>5</td>\n",
       "      <td>mean</td>\n",
       "      <td>layer</td>\n",
       "      <td>0.282115</td>\n",
       "      <td>0.004491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type               pretrained COMPOSITION_FUNC SIMILARITY_FUNC  \\\n",
       "0   dist_sim  EleutherAI/gpt-neo-1.3B     soft_cluster     dot_product   \n",
       "1   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "3   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "4   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "6   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "8   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "2   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "5   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "7   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "9   dist_sim  EleutherAI/gpt-neo-1.3B              NaN     dot_product   \n",
       "\n",
       "        encoding_scheme  num_fewshot WORD_AGG_SCHEME   NORM  hellaswag:acc  \\\n",
       "0  segment_each_example            0            last  layer       0.272655   \n",
       "1   concat_all_examples            0            mean  layer       0.289882   \n",
       "3   concat_each_example            0            last  layer       0.272655   \n",
       "4   concat_each_example            0            mean  layer       0.289882   \n",
       "6    merge_all_segments            0            mean  layer       0.289882   \n",
       "8  segment_each_example            0            mean  layer       0.289882   \n",
       "2   concat_all_examples            5            mean  layer       0.235909   \n",
       "5   concat_each_example            5            mean  layer       0.285103   \n",
       "7    merge_all_segments            5            mean  layer       0.282115   \n",
       "9  segment_each_example            5            mean  layer       0.282115   \n",
       "\n",
       "   hellaswag:acc_stderr  \n",
       "0              0.004444  \n",
       "1              0.004528  \n",
       "3              0.004444  \n",
       "4              0.004528  \n",
       "6              0.004528  \n",
       "8              0.004528  \n",
       "2              0.004237  \n",
       "5              0.004505  \n",
       "7              0.004491  \n",
       "9              0.004491  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_metrics(df, ['hellaswag:acc', 'webqs:acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv_lme': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a9a0c18e9779ed2e58fb5ce841cff9e897a8be01ea55109e48089b82d3eb788"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
